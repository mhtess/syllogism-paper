// HELPER FUNCTIONS
var foreach = function(lst, fn) {
  var foreach_ = function(i) {
    if (i < lst.length) {
      fn(lst[i]);
      foreach_(i + 1);
    }
  };
  foreach_(0);
};

var exponentiateRenormalize = function(dist, alpha){
  var probs = normalize(map(function(s){
    var p = Math.exp(dist.score(s))
    return Math.pow(p, alpha)
  }, dist.support()))
  return Categorical({
    vs: dist.support(),
    ps: probs
  })
}


var isChar = function(str, char){
  return str == char
}

var dataFrame = function(rawCSV) {
  return map(function(row) {
    return _.fromPairs(_.zip(rawCSV[0], row))
  }, rawCSV.slice(1))
}

var levels = function(df, label) {
  return _.uniq(_.map(df, label));
}

var MakeUniformDraw = function(lst) {
  return Categorical({
    vs: lst,
    ps: repeat(lst.length, function() {
      1
    })
  })
}

var displayDist = function(dist) {
  foreach(dist.support(), function(x) {
    display(x + ", " + Math.exp(dist.score(x)))
  })
}


var distProbs = function(dist, supp) {
  return map(function(s) {
    return Math.exp(dist.score(s))
  }, supp)
}

var KL = function(p, q, supp) {
  var P = distProbs(p, supp),
    Q = distProbs(q, supp);
  var diverge = function(xp, xq) {
    return xp == 0 ? 0 : (xp * Math.log(xp / xq));
  };
  return sum(map2(diverge, P, Q));
};


// STATE AND UTTERANCE FORMATTING
var formatSentence = function(sentence) {

  var quantifier = (sentence.quantifier == "nvc") ? "NVC" :
  (sentence.quantifier == "some_not") ? "Some not" :
  // (sentence.quantifier == "none") ? "No" :
   sentence.quantifier.charAt(0).toUpperCase() + sentence.quantifier.slice(1)

  return quantifier == "NVC" ? "NVC;" : quantifier + ";" + sentence.p1 + ";" + sentence.p2
}

var formatQuantifier = function(q) {
  q.toLowerCase().split(' ').join("_")
}

var stringToSyllogism = function(str) {
  _.fromPairs(_.zip(["quantifier", "p1", "p2"],
    mapIndexed(function(x, y) {
      return x == 0 ? formatQuantifier(y) : y
    }, str.split(';'))))
}


var parseVennDiagram = function(r) {
  map(function(i) {
    i[1] ? i[0] : ""
  }, _.toPairs(r)).join("")
}

var vennToString = function(venn){
  return filter(function(x){ x != null }, sort(map(function(v){
    v.truth_val ? v.label : null
  }, venn))).join(';')
}

var qudToString = function(venn, qud){
  var dimensionToOmit = "ABC".replace(qud.slice(0,1), "").replace(qud.slice(1,2), "")
  var qudVal = map(function(v){
      var label  = v.label
      return v.truth_val ? label.replace(dimensionToOmit, "") : null
    }, venn)
  var filteredQudVal = sort(_.uniq(
    filter(function(x){ x != null }, qudVal)
  ))
  return filteredQudVal.join(';')
}

var omitRegions = function(state, region_vals){
  return filter(function(s){ region_vals.indexOf(s.label) > -1 }, state)
}

var qudOmitRegions = function(state, region_vals){
  return vennToString(omitRegions(state, region_vals))
}

var marginalizeQUD_omitRegions = function(dist, region_vals){
  Enumerate(function(){
    var state = sample(dist)
    omitRegions(state, region_vals)
  })
}

var headPropQUD = function(state, sentence){
  return vennToString(filter(function(s){ s["label"].indexOf(sentence.p1) > -1 }, state))
}

var qudFn = function(state, qud){
  return qud == "state" ? vennToString(state) :
        _.isArray(qud) ? qudOmitRegions(state, qud) :
        _.isObject(qud) ? headPropQUD(state, qud) :
                        qudToString(state, qud)

}


var firstTermPreference = function(syllogism){
  return (isChar(syllogism[0].p1, "A") && !(isChar(syllogism[1].p1, "C"))) ? "A" :
  (!isChar(syllogism[0].p1, "A") && (isChar(syllogism[1].p1, "C"))) ? "C" :
  false
}


var predicate_filter = function(x, y) {
  return function(r) {
    return _.fromPairs([
      [x, r.region[x]],
      [y, r.region[y]]
    ])
  }
}


// SHOULD BE PAIRED WITH all()
// this DOES NOT includes an existential presupposition
var all_filter = function(x, y) {
  return function(r) {
    return r.region[x] ? // if its an A
      !r.region[y] ? // and not B
      !r.truth_val : // then it must be false
      true : // if it's an A and not a B, then it must be false
      true // if it's not an A, then it doesn't affect overall truthval (because we will use "all" to search that all are positive truth val)
  }
}

// SHOULD BE PAIRED WITH any()
// this includes an existential presupposition
var some_filter = function(x, y) {
  return function(r) {
    return r.region[x] ? // if its an A
      r.region[y] ? // and a B
      r.truth_val : // then this is the relevant region, and select its truthval
      false : // if it's an A and not a B, then it doesn't contribute a positive truth val (because we will use "any" to search for any positive truth val)
      false // if it's not an A, then it doesn't contribute a positive truth val (because we will use "any" to search for any positive truth val)
  }
}

var lexicon = {
  all: function(state, property1, property2) {
    return (all(all_filter(property1, property2), state) &&
      any(some_filter(property1, property2), state))
  },
  some: function(state, property1, property2) {
    return any(some_filter(property1, property2), state)
  },
  no: function(state, property1, property2) {
    return !(any(some_filter(property1, property2), state))
  },
  some_not: function(state, property1, property2) {
    return !(all(all_filter(property1, property2), state) &&
      any(some_filter(property1, property2), state))
    // return !(all(all_filter(property1, property2), state))
  },
  nvc: function(state, property1, property2) {
    return true
  }
}

var predicate_filter = function(x, y) {
  return function(r) {
    return _.fromPairs([
      [x, r.region[x]],
      [y, r.region[y]]
    ])
  }
}
var predicate_filter = function(x, y) {
  return function(r) {
    return _.fromPairs([
      [x, r.region[x]],
      [y, r.region[y]]
    ])
  }
}

///


var regions = Enumerate(function() {
  // return {
  //   A: flip(),
  //   B: flip(),
  //   C: flip()
  // }
  var A = flip(),
      B = flip(),
      C = flip()
  condition(A + B + C > 0)
  return {A, B, C}
}).support()

// display(regions)

// var venn_prior = Enumerate(function(){
// 	map(function(region){ return {region: region, truth_val: flip() } }, regions)
// })


var regionLabels = map(parseVennDiagram, regions)


var quantifiers = ["all", "some", "no", "some_not"]

// var conclusions = ["all", "some", "none", "some_not", "nvc"]

var conclusions = [
  {
    quantifier: "all",
    p1: "A",
    p2: "C"
  },
  {
    quantifier: "all",
    p1: "C",
    p2: "A"
  },
  {
    quantifier: "some",
    p1: "A",
    p2: "C"
  },
  {
    quantifier: "some",
    p1: "C",
    p2: "A"
  },
  {
    quantifier: "no",
    p1: "A",
    p2: "C"
  },
  {
    quantifier: "no",
    p1: "C",
    p2: "A"
  },
  {
    quantifier: "some_not",
    p1: "A",
    p2: "C"
  },
  {
    quantifier: "some_not",
    p1: "C",
    p2: "A"
  },
  {
    quantifier: "nvc",
    p1: "",
    p2: ""
  }
]



// var PremisePrior = cache(function(observed_premises){
// 	Infer({model: function(){
// 		map(function(obs_prm){
// 			return { p1: obs_prm.p1, p2: obs_prm.p2, quantifier: uniformDraw(quantifiers) }
// 		}, observed_premises)
// 	}})
// }


var alternative_quantifier_set_fn = cache(function(obs_prm) {
  MakeUniformDraw(map(function(q) {
    return {
      quantifier: q,
      p1: obs_prm.p1,
      p2: obs_prm.p2
    }
  }, quantifiers))
})

var alternative_quantifier_order_set_fn = cache(function(obs_prm) {
  MakeUniformDraw(map(function(q) {
    return {
      quantifier: q,
      p1: obs_prm.p1,
      p2: obs_prm.p2
    }
  }, quantifiers).concat({
    quantifier: obs_prm.quantifier,
    p1: obs_prm.p2,
    p2: obs_prm.p1
  }))
})

var alternative_set_maximal_fn = cache(function(obs_prm) {
  MakeUniformDraw(_.flatten(map(function(q) {
    return [{
        quantifier: q,
        p1: obs_prm.p1,
        p2: obs_prm.p2
      },
      {
        quantifier: q,
        p1: obs_prm.p2,
        p2: obs_prm.p1
      }
    ]
  }, quantifiers)))
})

var alternative_quantifier_set = cache(function(observed_premises) {
  map(alternative_quantifier_set_fn, observed_premises)
})

var alternative_quantifier_order_set = cache(function(observed_premises) {
  map(alternative_quantifier_order_set_fn, observed_premises)
})

var alternative_set_maximal = cache(function(observed_premises) {
  map(alternative_set_maximal_fn, observed_premises)
})

var alternatives = {
  quantifier: {
    single: alternative_quantifier_set_fn,
    double: alternative_quantifier_set
  },
  quantifierOrder: {
    single: alternative_quantifier_order_set_fn,
    double: alternative_quantifier_order_set,
  },
  maximal: {
    single: alternative_set_maximal_fn,
    double: alternative_set_maximal
  }
}

var alternative_set = alternatives["quantifier"]


// regions that increase in probability following the first premise
var sequentialQUDs = {
  'All;A;B': [ 'AB', 'ABC' ],
  'Some;A;B': [ 'A', 'AB', 'ABC', 'AC' ],
  'Some not;A;B': [ 'A', 'AB', 'ABC', 'AC' ], // this is the same as "some" because of pragmatics ("some" implies "not all", and visa versa)
  'No;A;B': [ 'A', 'AC', 'B', 'BC', 'C' ],
  'All;B;A': [ 'AB', 'ABC' ],
  'Some;B;A': [ 'AB', 'ABC', 'B', 'BC' ],
  'Some not;B;A': [ 'AB', 'ABC', 'B', 'BC' ],
  'No;B;A': [ 'A', 'AC', 'B', 'BC', 'C' ]
}

var regionExpectationFromVennDist = cache(function(venn_dist){
  var seq_region_dist = Infer({model: function(){
    var venn = sample(venn_dist);
    _.fromPairs(map(function(x){ return [x.label, x.truth_val] }, venn))
  }})
  var vennRegionLabels = _.keys(seq_region_dist.support()[0])

  return map(function(s){
    return [s, expectation(Enumerate(function(){
      var venn = sample(seq_region_dist)
      return venn[s]
    })) ]
  }, vennRegionLabels)
})

var marginalizeQUDval = function(stateDist){
  Infer({model: function(){
    var state = sample(stateDist)
    qudToString(state, "AC")
  }})
}

var makeConclusionPrior = cache(function(preferred_first_term, params){
  // give preference to conclusions that start with a "first term"
  // "first term" = unique first term used in premises
  var weights = map(function(c){
    c.quantifier == "nvc" ? params.nvcWeight :
    c.p1 == preferred_first_term ? params.firstTermPrefWeight : 1
  }, conclusions)
  return Categorical({vs: conclusions, ps: weights})
})


var makeVennPrior = cache(function(regionProbs){
  return Enumerate(function() {
    map2(function(region, priorProb) {
      var regionLabel = parseVennDiagram(region)
      return {
        region: region,
        priorProb: priorProb,
        truth_val: flip(priorProb),
        label: parseVennDiagram(region)
      }
      }, regions, regionProbs)
  })
})

var addNoise = function(dist, noise_param){
  Infer({ model: function(){
    flip(noise_param) ? formatSentence(uniformDraw(conclusions)) : sample(dist)
  }})
}

var marginalizeVennForR = function(dist){
  Infer({model: function(){
    var venn = sample(dist);
    _.fromPairs(map(function(x){ return [x.label, x.truth_val] }, venn))
  }})
}

var marginalizePremisesForR = function(dist){
  Infer({model: function(){
    var prems = sample(dist);
    return map(formatSentence, prems)
    // _.fromPairs(map(function(x){ return [x.label, x.truth_val] }, venn))
  }})
}
